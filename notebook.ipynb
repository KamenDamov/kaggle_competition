{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "aMTO_mUtK7Xy"
   },
   "source": [
    "# Importer les librairies, et fichiers .py auxiliaires"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aDxdetLcJCvp",
    "ExecuteTime": {
     "end_time": "2024-11-11T20:54:37.251210Z",
     "start_time": "2024-11-11T20:54:36.773851Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from preprocess_data import *\n",
    "from bayes_classifier import BayesClassifier\n",
    "from complement_naive_bayes import train_cnb_with_tfidf, train_cnb\n",
    "from ensemble_learning import train_ensemble\n",
    "from xgboost_classifier import train_xgboost, train_xgboost_with_tfidf\n",
    "from svc_classifier import *\n",
    "\n",
    "from save_output import save_output"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:54:37.734429Z",
     "start_time": "2024-11-11T20:54:37.253079Z"
    }
   },
   "source": [
    "data_preprocess = DataPreprocess()\n",
    "X_train, y_train, X_test = data_preprocess.train, data_preprocess.label_train, data_preprocess.test"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration de données"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:54:37.781214Z",
     "start_time": "2024-11-11T20:54:37.779965Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "sHdKFfvqLWn-"
   },
   "source": [
    "# Jalon 1) Naive de Bayes vanille\n",
    "K-Fold Validation croisée ($k = 7)$:\n",
    "- α: Lissage du postérieur de Bayes"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "iD7VY-FYJE02",
    "outputId": "a6dae65d-3d11-40f9-c380-6c51f2aef693",
    "ExecuteTime": {
     "end_time": "2024-11-11T20:55:07.589274Z",
     "start_time": "2024-11-11T20:54:37.845990Z"
    }
   },
   "source": [
    "bayes_classifier = BayesClassifier()\n",
    "best_lps, best_f1 = bayes_classifier.hyperparameter_tuning(X_train, y_train)\n",
    "print(best_lps, best_f1)\n",
    "tuned_bayes_classifier = BayesClassifier()\n",
    "tuned_bayes_classifier.fit(X_train, y_train, best_lps)\n",
    "predictions = np.array([tuned_bayes_classifier.predict(x_i) for x_i in X_test])\n",
    "save_output(predictions, \"bayes\", best_lps, \"stopwords\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:29<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9499999999999998 0.5965643817273643\n",
      "predictions saved in output/20241111/155507_bayes_0.9499999999999998_stopwords.csv\n",
      "already same predictions saved in submissions? None\n",
      "already same predictions saved in output?\n",
      "\t None\n",
      "Number of 0: 1658\n",
      "Number of 1: 698\n",
      "Ratio of 1: 0.29626485568760613\n",
      "Number of differences with bayes classifier submission: 3\n",
      "Ratio of 1 in bayes submission: 0.29499151103565363\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jalon 2)\n",
    "# Naive Bayes Complement\n",
    "K-Fold validation croisée stratifiée ($k = 5)$:\n",
    "- α: Lissage du postérieur de Bayes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prétraitement: TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:55:12.205620Z",
     "start_time": "2024-11-11T20:55:07.594189Z"
    }
   },
   "source": [
    "complement_naive_bayes, tfidf_transformer = train_cnb_with_tfidf(X_train, y_train)\n",
    "tfidf_test = tfidf_transformer.transform(X_test)\n",
    "predictions = complement_naive_bayes.predict(tfidf_test)\n",
    "save_output(predictions, \"cnb\", \"random_search_50_iter\", \"tfidf\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END .....cnb__alpha=0.5619101782710437;, score=0.111 total time=   1.4s\n",
      "[CV 2/2] END .....cnb__alpha=0.5619101782710437;, score=0.110 total time=   1.4s\n",
      "Best Parameters: {'cnb__alpha': 0.5619101782710437}\n",
      "Best F1 Score: 0.11089093184257118\n",
      "predictions saved in output/20241111/155512_cnb_random_search_50_iter_tfidf.csv\n",
      "already same predictions saved in submissions? None\n",
      "already same predictions saved in output?\n",
      "\t output/20241111/154325_cnb_random_search_50_iter_tfidf.csv\n",
      "\t output/20241111/154450_cnb_random_search_50_iter_tfidf.csv\n",
      "\t output/20241111/154831_cnb_random_search_50_iter_tfidf.csv\n",
      "\t output/20241110/170114_cnb_random_search_50_iter_tfidf.csv\n",
      "\t output/20241110/165637_cnb_random_search_50_iter_tfidf.csv\n",
      "\t output/20241110/170636_cnb_random_search_50_iter_tfidf.csv\n",
      "\t output/20241110/170853_cnb_random_search_50_iter_tfidf.csv\n",
      "\t output/20241110/170443_cnb_random_search_50_iter_tfidf.csv\n",
      "\t output/20241110/170353_cnb_random_search_50_iter_tfidf.csv\n",
      "\t output/20241110/164836_cnb_random_search_50_iter_tfidf.csv\n",
      "\t output/20241110/171135_cnb_random_search_50_iter_tfidf.csv\n",
      "\t output/20241110/165028_cnb_random_search_50_iter_tfidf.csv\n",
      "\t output/20241110/170556_cnb_random_search_50_iter_tfidf.csv\n",
      "\t output/20241110/171250_cnb_random_search_50_iter_tfidf.csv\n",
      "\t output/20241110/170254_cnb_random_search_50_iter_tfidf.csv\n",
      "\t output/20241110/165845_cnb_random_search_50_iter_tfidf.csv\n",
      "Number of 0: 1925\n",
      "Number of 1: 431\n",
      "Ratio of 1: 0.18293718166383702\n",
      "Number of differences with bayes classifier submission: 294\n",
      "Ratio of 1 in bayes submission: 0.29499151103565363\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prétraitement: Sans prétraitement"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:55:14.086754Z",
     "start_time": "2024-11-11T20:55:12.210957Z"
    }
   },
   "source": [
    "complement_naive_bayes = train_cnb(X_train, y_train)\n",
    "predictions = complement_naive_bayes.predict(X_test)\n",
    "save_output(predictions, \"cnb\", \"random_search_50_iter\", \"no_preprocessing\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END .....cnb__alpha=0.5619101782710437;, score=0.588 total time=   0.5s\n",
      "[CV 2/2] END .....cnb__alpha=0.5619101782710437;, score=0.575 total time=   0.5s\n",
      "Best Parameters: {'cnb__alpha': 0.5619101782710437}\n",
      "Best F1 Score: 0.581482890607508\n",
      "predictions saved in output/20241111/155514_cnb_random_search_50_iter_no_preprocessing.csv\n",
      "already same predictions saved in submissions? None\n",
      "already same predictions saved in output?\n",
      "\t output/20241111/154833_cnb_random_search_50_iter_no_preprocessing.csv\n",
      "\t output/20241111/154327_cnb_random_search_50_iter_no_preprocessing.csv\n",
      "\t output/20241111/154452_cnb_random_search_50_iter_no_preprocessing.csv\n",
      "\t output/20241110/172138_cnb_random_search_50_iter_no_preprocessing.csv\n",
      "Number of 0: 1544\n",
      "Number of 1: 812\n",
      "Ratio of 1: 0.34465195246179964\n",
      "Number of differences with bayes classifier submission: 117\n",
      "Ratio of 1 in bayes submission: 0.29499151103565363\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prétraitement: TFIDF, réduction par arbre, stopwords retirés"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:55:27.207603Z",
     "start_time": "2024-11-11T20:55:14.092589Z"
    }
   },
   "source": [
    "data_preprocess = DataPreprocess()\n",
    "data_preprocess.remove_stopwords()\n",
    "X_train, sorted_indeces_features = tree_based_dimensionality_reduction(data_preprocess.train, data_preprocess.label_train)\n",
    "X_test = data_preprocess.test[:, sorted_indeces_features]\n",
    "complement_naive_bayes = train_cnb(X_train, data_preprocess.label_train)\n",
    "predictions = complement_naive_bayes.predict(X_test)\n",
    "save_output(predictions, \"cnb\", \"random_search_50_iter\", \"tree_reduction_stopwords_tfidf\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END .....cnb__alpha=0.5619101782710437;, score=0.559 total time=   0.0s\n",
      "[CV 2/2] END .....cnb__alpha=0.5619101782710437;, score=0.555 total time=   0.0s\n",
      "Best Parameters: {'cnb__alpha': 0.5619101782710437}\n",
      "Best F1 Score: 0.5571885009594754\n",
      "predictions saved in output/20241111/155527_cnb_random_search_50_iter_tree_reduction_stopwords_tfidf.csv\n",
      "already same predictions saved in submissions? None\n",
      "already same predictions saved in output?\n",
      "\t output/20241111/154846_cnb_random_search_50_iter_tree_reduction_stopwords_tfidf.csv\n",
      "Number of 0: 1505\n",
      "Number of 1: 851\n",
      "Ratio of 1: 0.36120543293718166\n",
      "Number of differences with bayes classifier submission: 320\n",
      "Ratio of 1 in bayes submission: 0.29499151103565363\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC\n",
    "Grid Search, K-Fold validation croisée stratifiée ($k = 5)$, avec hyperparamètres:\n",
    "- $\\gamma$ : Coefficient du Noyau RBF\n",
    "- $C$ : Terme de régularization pour la pénalité euclidienne."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prétraitement: Retrirer stopwords, Réduction par somme cumulative, sous-échantillonage aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T21:07:00.835596Z",
     "start_time": "2024-11-11T21:03:22.535860Z"
    }
   },
   "source": [
    "data_preprocess = DataPreprocess()\n",
    "data_preprocess.remove_stopwords()\n",
    "indeces_to_remove = remove_cum_sum(data_preprocess.train, 0.95)\n",
    "data_preprocess.train = np.delete(data_preprocess.train, indeces_to_remove, axis=1)\n",
    "data_preprocess.test = np.delete(data_preprocess.test, indeces_to_remove, axis=1)\n",
    "X_train_undersampled, y_train_undersampled = random_undersampling(data_preprocess.train, data_preprocess.label_train)\n",
    "\n",
    "best_params_, best_score_ = train_svc(X_train_undersampled, y_train_undersampled)\n",
    "print(best_params_, best_score_)\n",
    "svc = SVC(kernel='rbf', C=best_params_['C'], gamma=best_params_['gamma'])\n",
    "svc.fit(X_train_undersampled, y_train_undersampled)\n",
    "y_pred = svc.predict(data_preprocess.test)\n",
    "params = f\"C={best_params_['C']}, gamma={best_params_['gamma']}\"\n",
    "save_output(y_pred, \"svm\", params, \"stopwords_cum-sum_undersampled\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': [0.003], 'C': [45]}\n",
      "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
      "[CV 1/1] END .................C=45, gamma=0.003;, score=0.635 total time=  51.1s\n",
      "{'C': 45, 'gamma': 0.003} 0.6349442379182156\n",
      "predictions saved in output/20241111/160700_svm_C=45, gamma=0.003_stopwords_cum-sum_undersampled.csv\n",
      "already same predictions saved in submissions? None\n",
      "already same predictions saved in output?\n",
      "\t None\n",
      "Number of 0: 1615\n",
      "Number of 1: 741\n",
      "Ratio of 1: 0.31451612903225806\n",
      "Number of differences with bayes classifier submission: 426\n",
      "Ratio of 1 in bayes submission: 0.29499151103565363\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGDClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "Random Search, K-Fold validation croisée stratifiée ($k = 5)$, avec hyperparamètres:\n",
    "- Learning rate: Taille du pas lors de la descente de critère sur la perte (gain de subdivision) \n",
    "- Nombre d'estimateurs (n_estimators): Nombre d'arbres de décision\n",
    "- Profondeur maximale (max_depth): Profondeur maximale de chaque arbre (nombre de branchements max)\n",
    "- sous-échantillon (subsample):  Proportion de données utilisées pour produire chaque arbre."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prétraitement: Sur-échantillonnage bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:57:27.378729618Z",
     "start_time": "2024-11-11T20:52:58.511635Z"
    }
   },
   "source": [
    "data_preprocess = DataPreprocess()\n",
    "data_preprocess.remove_stopwords()\n",
    "x_train_oversampled, y_train_oversampled = boostrap_oversampling(data_preprocess.train, data_preprocess.label_train)\n",
    "xgboost_classifier, tfidf_transformer = train_xgboost(x_train_oversampled, y_train_oversampled)\n",
    "predictions = xgboost_classifier.predict(data_preprocess.test)\n",
    "save_output(predictions, \"xgboost\", \"random_search_15_iter\", \"stopwords_bootstrap\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'model' for estimator Pipeline(steps=[('xgboost',\n                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n                               colsample_bylevel=None, colsample_bynode=None,\n                               colsample_bytree=None, device=None,\n                               early_stopping_rounds=None,\n                               enable_categorical=False, eval_metric=None,\n                               feature_types=None, gamma=None, grow_policy=None,\n                               importance_type=None,\n                               interaction_constraints=None, learning_rate=None,\n                               max_bin=None, max_cat_threshold=None,\n                               max_cat_to_onehot=None, max_delta_step=None,\n                               max_depth=None, max_leaves=None,\n                               min_child_weight=None, missing=nan,\n                               monotone_constraints=None, multi_strategy=None,\n                               n_estimators=None, n_jobs=None,\n                               num_parallel_tree=None, random_state=None, ...))]). Valid parameters are: ['memory', 'steps', 'verbose'].",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m data_preprocess\u001B[38;5;241m.\u001B[39mremove_stopwords()\n\u001B[1;32m      3\u001B[0m x_train_oversampled, y_train_oversampled \u001B[38;5;241m=\u001B[39m boostrap_oversampling(data_preprocess\u001B[38;5;241m.\u001B[39mtrain, data_preprocess\u001B[38;5;241m.\u001B[39mlabel_train)\n\u001B[0;32m----> 4\u001B[0m xgboost_classifier, tfidf_transformer \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_xgboost\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train_oversampled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_oversampled\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m predictions \u001B[38;5;241m=\u001B[39m xgboost_classifier\u001B[38;5;241m.\u001B[39mpredict(data_preprocess\u001B[38;5;241m.\u001B[39mtest)\n\u001B[1;32m      6\u001B[0m save_output(predictions, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxgboost\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrandom_search_15_iter\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstopwords_bootstrap\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/kaggle_competition/xgboost_classifier.py:63\u001B[0m, in \u001B[0;36mtrain_xgboost\u001B[0;34m(X_train, y_train)\u001B[0m\n\u001B[1;32m     56\u001B[0m scorer \u001B[38;5;241m=\u001B[39m make_scorer(f1_score)\n\u001B[1;32m     58\u001B[0m random_search \u001B[38;5;241m=\u001B[39m RandomizedSearchCV(\n\u001B[1;32m     59\u001B[0m     pipeline, param_distributions, scoring\u001B[38;5;241m=\u001B[39mscorer, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, \n\u001B[1;32m     60\u001B[0m     verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, n_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m\n\u001B[1;32m     61\u001B[0m )\n\u001B[0;32m---> 63\u001B[0m \u001B[43mrandom_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     65\u001B[0m best_params \u001B[38;5;241m=\u001B[39m random_search\u001B[38;5;241m.\u001B[39mbest_params_\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest Parameters:\u001B[39m\u001B[38;5;124m\"\u001B[39m, best_params)\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.08/lib/python3.9/site-packages/sklearn/base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1471\u001B[0m     )\n\u001B[1;32m   1472\u001B[0m ):\n\u001B[0;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.08/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1019\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, **params)\u001B[0m\n\u001B[1;32m   1013\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[1;32m   1014\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[1;32m   1015\u001B[0m     )\n\u001B[1;32m   1017\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m-> 1019\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1021\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[1;32m   1022\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[1;32m   1023\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.08/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1960\u001B[0m, in \u001B[0;36mRandomizedSearchCV._run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1958\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[1;32m   1959\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1960\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1961\u001B[0m \u001B[43m        \u001B[49m\u001B[43mParameterSampler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1962\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_distributions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_iter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_state\u001B[49m\n\u001B[1;32m   1963\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1964\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.08/lib/python3.9/site-packages/sklearn/model_selection/_search.py:965\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    957\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    958\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m    959\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    960\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    961\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[1;32m    962\u001B[0m         )\n\u001B[1;32m    963\u001B[0m     )\n\u001B[0;32m--> 965\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    966\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    967\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    968\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    969\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    970\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    971\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    972\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    973\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    974\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    975\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    976\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    977\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    978\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    979\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplitter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    980\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    981\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    983\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    984\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    985\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    986\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    987\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    988\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.08/lib/python3.9/site-packages/sklearn/utils/parallel.py:74\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m     69\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[1;32m     70\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     71\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[1;32m     73\u001B[0m )\n\u001B[0;32m---> 74\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.08/lib/python3.9/site-packages/joblib/parallel.py:1918\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1916\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_sequential_output(iterable)\n\u001B[1;32m   1917\u001B[0m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[0;32m-> 1918\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1920\u001B[0m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[1;32m   1921\u001B[0m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[1;32m   1922\u001B[0m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[1;32m   1923\u001B[0m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[1;32m   1924\u001B[0m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[1;32m   1925\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.08/lib/python3.9/site-packages/joblib/parallel.py:1847\u001B[0m, in \u001B[0;36mParallel._get_sequential_output\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1845\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_batches \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1846\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m-> 1847\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1848\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_completed_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1849\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_progress()\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.08/lib/python3.9/site-packages/sklearn/utils/parallel.py:136\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    134\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    135\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[0;32m--> 136\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.08/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:876\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[1;32m    869\u001B[0m score_params_test \u001B[38;5;241m=\u001B[39m _check_method_params(X, params\u001B[38;5;241m=\u001B[39mscore_params, indices\u001B[38;5;241m=\u001B[39mtest)\n\u001B[1;32m    871\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m parameters \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    872\u001B[0m     \u001B[38;5;66;03m# here we clone the parameters, since sometimes the parameters\u001B[39;00m\n\u001B[1;32m    873\u001B[0m     \u001B[38;5;66;03m# themselves might be estimators, e.g. when we search over different\u001B[39;00m\n\u001B[1;32m    874\u001B[0m     \u001B[38;5;66;03m# estimators in a pipeline.\u001B[39;00m\n\u001B[1;32m    875\u001B[0m     \u001B[38;5;66;03m# ref: https://github.com/scikit-learn/scikit-learn/pull/26786\u001B[39;00m\n\u001B[0;32m--> 876\u001B[0m     estimator \u001B[38;5;241m=\u001B[39m \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_params\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msafe\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    878\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m    880\u001B[0m X_train, y_train \u001B[38;5;241m=\u001B[39m _safe_split(estimator, X, y, train)\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.08/lib/python3.9/site-packages/sklearn/pipeline.py:237\u001B[0m, in \u001B[0;36mPipeline.set_params\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m    218\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mset_params\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    219\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Set the parameters of this estimator.\u001B[39;00m\n\u001B[1;32m    220\u001B[0m \n\u001B[1;32m    221\u001B[0m \u001B[38;5;124;03m    Valid parameter keys can be listed with ``get_params()``. Note that\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;124;03m        Pipeline class instance.\u001B[39;00m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 237\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_set_params\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msteps\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    238\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.08/lib/python3.9/site-packages/sklearn/utils/metaestimators.py:69\u001B[0m, in \u001B[0;36m_BaseComposition._set_params\u001B[0;34m(self, attr, **params)\u001B[0m\n\u001B[1;32m     66\u001B[0m                 \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_replace_estimator(attr, name, params\u001B[38;5;241m.\u001B[39mpop(name))\n\u001B[1;32m     68\u001B[0m \u001B[38;5;66;03m# 3. Step parameters and other initialisation arguments\u001B[39;00m\n\u001B[0;32m---> 69\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_params\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/rapids-24.08/lib/python3.9/site-packages/sklearn/base.py:279\u001B[0m, in \u001B[0;36mBaseEstimator.set_params\u001B[0;34m(self, **params)\u001B[0m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m valid_params:\n\u001B[1;32m    278\u001B[0m     local_valid_params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_param_names()\n\u001B[0;32m--> 279\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    280\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid parameter \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m for estimator \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    281\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mValid parameters are: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlocal_valid_params\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    282\u001B[0m     )\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m delim:\n\u001B[1;32m    285\u001B[0m     nested_params[key][sub_key] \u001B[38;5;241m=\u001B[39m value\n",
      "\u001B[0;31mValueError\u001B[0m: Invalid parameter 'model' for estimator Pipeline(steps=[('xgboost',\n                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n                               colsample_bylevel=None, colsample_bynode=None,\n                               colsample_bytree=None, device=None,\n                               early_stopping_rounds=None,\n                               enable_categorical=False, eval_metric=None,\n                               feature_types=None, gamma=None, grow_policy=None,\n                               importance_type=None,\n                               interaction_constraints=None, learning_rate=None,\n                               max_bin=None, max_cat_threshold=None,\n                               max_cat_to_onehot=None, max_delta_step=None,\n                               max_depth=None, max_leaves=None,\n                               min_child_weight=None, missing=nan,\n                               monotone_constraints=None, multi_strategy=None,\n                               n_estimators=None, n_jobs=None,\n                               num_parallel_tree=None, random_state=None, ...))]). Valid parameters are: ['memory', 'steps', 'verbose']."
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prétraitement: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage par Ensemble"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensmeble: CNB, XGBoost, Logistic Regression sans stopwords, sous-échantillonage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prétraitement : sans stopwords, sous-échantillonage, réduction de dimension par somme cumulative"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:57:27.379771503Z",
     "start_time": "2024-11-11T20:52:06.043030Z"
    }
   },
   "source": [
    "data_preprocess = DataPreprocess()\n",
    "data_preprocess.remove_stopwords()\n",
    "indeces_to_remove =remove_cum_sum(data_preprocess.train, 0.95)\n",
    "data_preprocess.train = np.delete(data_preprocess.train, indeces_to_remove, axis=1)\n",
    "data_preprocess.test = np.delete(data_preprocess.test, indeces_to_remove, axis=1)\n",
    "X_train_undersampled, y_train_undersampled = random_undersampling(data_preprocess.train, data_preprocess.label_train)\n",
    "model_names = ['ComplementNB', 'XGBoost', 'LogisticRegression']\n",
    "best_ensemble_model = train_ensemble(X_train_undersampled, y_train_undersampled, model_names)\n",
    "predictions_voter = best_ensemble_model.predict(data_preprocess.test)\n",
    "save_output(predictions_voter, \"ensemble_cnb_xgboost_logreg\", \"random_search_15_iter\", \"stopwords_undersampling_cumulative_sum\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END ...model__alpha=0.3851694527491273;, score=0.694 total time=   0.1s\n",
      "[CV 2/2] END ...model__alpha=0.3851694527491273;, score=0.685 total time=   0.1s\n",
      "Best F1 for ComplementNB: 0.6895566521985158\n",
      "Confusion Matrix - Fold 1:\n",
      "[[1329  452]\n",
      " [ 298  851]]\n",
      "\n",
      "Confusion Matrix - Fold 2:\n",
      "[[1279  502]\n",
      " [ 289  860]]\n",
      "\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ggenois/anaconda3/envs/rapids-24.08/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [15:52:07] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1722516643542/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END model__learning_rate=0.11976270078546496, model__max_depth=5, model__n_estimators=200, model__subsample=0.8411053504286575;, score=0.630 total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ggenois/anaconda3/envs/rapids-24.08/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [15:52:09] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1722516643542/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END model__learning_rate=0.11976270078546496, model__max_depth=5, model__n_estimators=200, model__subsample=0.8411053504286575;, score=0.635 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ggenois/anaconda3/envs/rapids-24.08/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [15:52:11] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1722516643542/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 for XGBClassifier: 0.6321269577091664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ggenois/anaconda3/envs/rapids-24.08/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [15:52:13] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1722516643542/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ggenois/anaconda3/envs/rapids-24.08/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [15:52:15] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1722516643542/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix - Fold 1:\n",
      "[[1500  281]\n",
      " [ 492  657]]\n",
      "\n",
      "Confusion Matrix - Fold 2:\n",
      "[[1452  329]\n",
      " [ 462  687]]\n",
      "\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END model__C=5.588135039273247, model__penalty=l1, model__solver=liblinear;, score=0.581 total time=   0.1s\n",
      "[CV 2/2] END model__C=5.588135039273247, model__penalty=l1, model__solver=liblinear;, score=0.600 total time=   0.1s\n",
      "Best F1 for LogisticRegression: 0.5907665275877441\n",
      "Confusion Matrix - Fold 1:\n",
      "[[1332  449]\n",
      " [ 494  655]]\n",
      "\n",
      "Confusion Matrix - Fold 2:\n",
      "[[1304  477]\n",
      " [ 451  698]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ggenois/anaconda3/envs/rapids-24.08/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [15:52:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1722516643542/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions saved in output/20241111/155220_ensemble_cnb_xgboost_logreg_random_search_15_iter_stopwords_undersampling_cumulative_sum.csv\n",
      "already same predictions saved in submissions? None\n",
      "already same predictions saved in output?\n",
      "\t None\n",
      "Number of 0: 1569\n",
      "Number of 1: 787\n",
      "Ratio of 1: 0.3340407470288625\n",
      "Number of differences with bayes classifier submission: 250\n",
      "Ratio of 1 in bayes submission: 0.29499151103565363\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prétraitement : sans stopwords, sous-échantillonage"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:57:27.379981242Z",
     "start_time": "2024-11-11T20:52:20.612805Z"
    }
   },
   "source": [
    "data_preprocess = DataPreprocess()\n",
    "data_preprocess.remove_stopwords()\n",
    "X_train_undersampled, y_train_undersampled = random_undersampling(data_preprocess.train, data_preprocess.label_train)\n",
    "model_names = ['ComplementNB', 'XGBoost', 'LogisticRegression']\n",
    "best_ensemble_model = train_ensemble(X_train_undersampled, y_train_undersampled, model_names)\n",
    "predictions_voter = best_ensemble_model.predict(data_preprocess.test)\n",
    "save_output(predictions_voter, \"ensemble_cnb_xgboost_logreg\", \"random_search_15_iter\", \"stopwords_undersampling_cumulative_sum\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END ...model__alpha=0.3851694527491273;, score=0.687 total time=   0.4s\n",
      "[CV 2/2] END ...model__alpha=0.3851694527491273;, score=0.683 total time=   0.4s\n",
      "Best F1 for ComplementNB: 0.6849461126344383\n",
      "Confusion Matrix - Fold 1:\n",
      "[[1298  483]\n",
      " [ 296  853]]\n",
      "\n",
      "Confusion Matrix - Fold 2:\n",
      "[[1275  506]\n",
      " [ 290  859]]\n",
      "\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ggenois/anaconda3/envs/rapids-24.08/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [15:52:25] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1722516643542/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END model__learning_rate=0.11976270078546496, model__max_depth=5, model__n_estimators=200, model__subsample=0.8411053504286575;, score=0.630 total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ggenois/anaconda3/envs/rapids-24.08/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [15:52:29] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1722516643542/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END model__learning_rate=0.11976270078546496, model__max_depth=5, model__n_estimators=200, model__subsample=0.8411053504286575;, score=0.635 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ggenois/anaconda3/envs/rapids-24.08/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [15:52:33] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1722516643542/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 for XGBClassifier: 0.6321269577091664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ggenois/anaconda3/envs/rapids-24.08/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [15:52:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1722516643542/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/ggenois/anaconda3/envs/rapids-24.08/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [15:52:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1722516643542/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix - Fold 1:\n",
      "[[1500  281]\n",
      " [ 492  657]]\n",
      "\n",
      "Confusion Matrix - Fold 2:\n",
      "[[1452  329]\n",
      " [ 462  687]]\n",
      "\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END model__C=5.588135039273247, model__penalty=l1, model__solver=liblinear;, score=0.587 total time=   0.3s\n",
      "[CV 2/2] END model__C=5.588135039273247, model__penalty=l1, model__solver=liblinear;, score=0.604 total time=   0.3s\n",
      "Best F1 for LogisticRegression: 0.5959325131042796\n",
      "Confusion Matrix - Fold 1:\n",
      "[[1350  431]\n",
      " [ 492  657]]\n",
      "\n",
      "Confusion Matrix - Fold 2:\n",
      "[[1306  475]\n",
      " [ 447  702]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ggenois/anaconda3/envs/rapids-24.08/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [15:52:51] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1722516643542/work/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions saved in output/20241111/155258_ensemble_cnb_xgboost_logreg_random_search_15_iter_stopwords_undersampling_cumulative_sum.csv\n",
      "already same predictions saved in submissions? None\n",
      "already same predictions saved in output?\n",
      "\t None\n",
      "Number of 0: 1569\n",
      "Number of 1: 787\n",
      "Ratio of 1: 0.3340407470288625\n",
      "Number of differences with bayes classifier submission: 236\n",
      "Ratio of 1 in bayes submission: 0.29499151103565363\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
