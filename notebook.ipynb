{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "aMTO_mUtK7Xy"
   },
   "source": [
    "# Importer les librairies, et fichiers .py auxiliaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:54:37.251210Z",
     "start_time": "2024-11-11T20:54:36.773851Z"
    },
    "id": "aDxdetLcJCvp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from preprocess_data import *\n",
    "from bayes_classifier import BayesClassifier\n",
    "from complement_naive_bayes import train_cnb_with_tfidf, train_cnb\n",
    "from ensemble_learning import train_ensemble\n",
    "from xgboost_classifier import train_xgboost, train_xgboost_with_tfidf\n",
    "from svc_classifier import *\n",
    "from sgd_classifier import *\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from save_output import save_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:54:37.734429Z",
     "start_time": "2024-11-11T20:54:37.253079Z"
    }
   },
   "outputs": [],
   "source": [
    "data_preprocess = DataPreprocess()\n",
    "X_train, y_train, X_test = data_preprocess.train, data_preprocess.label_train, data_preprocess.test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:54:37.781214Z",
     "start_time": "2024-11-11T20:54:37.779965Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "sHdKFfvqLWn-"
   },
   "source": [
    "# Jalon 1) Naive de Bayes vanille\n",
    "K-Fold Validation croisée ($k = 7)$:\n",
    "- α: Lissage du postérieur de Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:55:07.589274Z",
     "start_time": "2024-11-11T20:54:37.845990Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "iD7VY-FYJE02",
    "outputId": "a6dae65d-3d11-40f9-c380-6c51f2aef693"
   },
   "outputs": [],
   "source": [
    "bayes_classifier = BayesClassifier()\n",
    "best_lps, best_f1 = bayes_classifier.hyperparameter_tuning(X_train, y_train)\n",
    "print(best_lps, best_f1)\n",
    "tuned_bayes_classifier = BayesClassifier()\n",
    "tuned_bayes_classifier.fit(X_train, y_train, best_lps)\n",
    "predictions = np.array([tuned_bayes_classifier.predict(x_i) for x_i in X_test])\n",
    "save_output(predictions, \"bayes\", best_lps, \"stopwords\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jalon 2)\n",
    "# Naive Bayes Complement\n",
    "K-Fold validation croisée stratifiée ($k = 5)$:\n",
    "- α: Lissage du postérieur de Bayes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prétraitement: TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:55:12.205620Z",
     "start_time": "2024-11-11T20:55:07.594189Z"
    }
   },
   "outputs": [],
   "source": [
    "complement_naive_bayes, tfidf_transformer = train_cnb_with_tfidf(X_train, y_train)\n",
    "tfidf_test = tfidf_transformer.transform(X_test)\n",
    "predictions = complement_naive_bayes.predict(tfidf_test)\n",
    "save_output(predictions, \"cnb\", \"random_search_50_iter\", \"tfidf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prétraitement: Sans prétraitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:55:14.086754Z",
     "start_time": "2024-11-11T20:55:12.210957Z"
    }
   },
   "outputs": [],
   "source": [
    "complement_naive_bayes = train_cnb(X_train, y_train)\n",
    "predictions = complement_naive_bayes.predict(X_test)\n",
    "save_output(predictions, \"cnb\", \"random_search_50_iter\", \"no_preprocessing\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prétraitement: TFIDF, réduction par arbre, stopwords retirés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:55:27.207603Z",
     "start_time": "2024-11-11T20:55:14.092589Z"
    }
   },
   "outputs": [],
   "source": [
    "data_preprocess = DataPreprocess()\n",
    "data_preprocess.remove_stopwords()\n",
    "X_train, sorted_indeces_features = tree_based_dimensionality_reduction(data_preprocess.train, data_preprocess.label_train)\n",
    "X_test = data_preprocess.test[:, sorted_indeces_features]\n",
    "complement_naive_bayes, tfidf_transformer = train_cnb_with_tfidf(X_train, data_preprocess.label_train)\n",
    "tfidf_test = tfidf_transformer.transform(X_test)\n",
    "predictions = complement_naive_bayes.predict(tfidf_test)\n",
    "save_output(predictions, \"cnb\", \"random_search_50_iter\", \"tree_reduction_stopwords_tfidf\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prétraitement: TFIDF, réduction par arbre, stopwords retirés, suréchantillonnage SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocess = DataPreprocess()\n",
    "data_preprocess.remove_stopwords()\n",
    "X_train, sorted_indeces_features = tree_based_dimensionality_reduction(data_preprocess.train, data_preprocess.label_train)\n",
    "X_test = data_preprocess.test[:, sorted_indeces_features]\n",
    "X_train, y_train = smote_oversampling(data_preprocess.train, data_preprocess.label_train)\n",
    "\n",
    "complement_naive_bayes = train_cnb(X_train, y_train)\n",
    "tfidf_test = tfidf_transformer.transform(X_test)\n",
    "predictions = complement_naive_bayes.predict(tfidf_test)\n",
    "\n",
    "save_output(predictions, \"cnb\", \"random_search_50_iter\", \"tree_reduction_stopwords_tfidf_smote\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC\n",
    "Grid Search, K-Fold validation croisée stratifiée ($k = 5)$, avec hyperparamètres:\n",
    "- $\\gamma$ : Coefficient du Noyau RBF\n",
    "- $C$ : Terme de régularization pour la pénalité euclidienne."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prétraitement: Retrirer stopwords, Réduction par somme cumulative, sous-échantillonage aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T21:07:00.835596Z",
     "start_time": "2024-11-11T21:03:22.535860Z"
    }
   },
   "outputs": [],
   "source": [
    "data_preprocess = DataPreprocess()\n",
    "data_preprocess.remove_stopwords()\n",
    "indeces_to_remove = remove_cum_sum(data_preprocess.train, 0.95)\n",
    "data_preprocess.train = np.delete(data_preprocess.train, indeces_to_remove, axis=1)\n",
    "data_preprocess.test = np.delete(data_preprocess.test, indeces_to_remove, axis=1)\n",
    "X_train_undersampled, y_train_undersampled = random_undersampling(data_preprocess.train, data_preprocess.label_train)\n",
    "\n",
    "best_params_, best_score_ = train_svc(X_train_undersampled, y_train_undersampled)\n",
    "print(best_params_, best_score_)\n",
    "svc = SVC(kernel='rbf', C=best_params_['C'], gamma=best_params_['gamma'])\n",
    "svc.fit(X_train_undersampled, y_train_undersampled)\n",
    "y_pred = svc.predict(data_preprocess.test)\n",
    "params = f\"C={best_params_['C']}, gamma={best_params_['gamma']}\"\n",
    "save_output(y_pred, \"svm\", params, \"stopwords_cum-sum_undersampled\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGDClassifier\n",
    "Random Search, K-Fold validation croisée stratifiée ($k = 5)$, avec hyperparamètres:\n",
    "- loss: ModifiedHuber \n",
    "- penalty: ElaticNet \n",
    "- l1_ratio: Porportion de la perte d'ElasticNet qui est l1.\n",
    "- $\\alpha$: Poids attribué au terme de régularisation. Une plus grande valeur favorise que certains coefficients soient annulés (par l1) ou fortement adoucis (par l2) quand la pénalité est ElaticNet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocess = DataPreprocess()\n",
    "data_preprocess.remove_stopwords()\n",
    "indeces_to_remove = remove_cum_sum(data_preprocess.train, 0.95)\n",
    "data_preprocess.train = np.delete(data_preprocess.train, indeces_to_remove, axis=1)\n",
    "data_preprocess.test = np.delete(data_preprocess.test, indeces_to_remove, axis=1)\n",
    "X_train_undersampled, y_train_undersampled = random_undersampling(data_preprocess.train, data_preprocess.label_train)\n",
    "\n",
    "best_sgd = train_ensemble(X_train_undersampled, y_train_undersampled)\n",
    "predictions_voter = train_sgd.predict(data_preprocess.test)\n",
    "save_output(predictions_voter, \"sgd\", \"random_search_15_iter\", \"stopwords_undersampling_cumulative_sum\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "Random Search, K-Fold validation croisée stratifiée ($k = 5)$, avec hyperparamètres:\n",
    "- Learning rate: Taille du pas lors de la descente de critère sur la perte (gain de subdivision) \n",
    "- Nombre d'estimateurs (n_estimators): Nombre d'arbres de décision\n",
    "- Profondeur maximale (max_depth): Profondeur maximale de chaque arbre (nombre de branchements max)\n",
    "- sous-échantillon (subsample):  Proportion de données utilisées pour produire chaque arbre."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prétraitement: Sur-échantillonnage bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:57:27.378729618Z",
     "start_time": "2024-11-11T20:52:58.511635Z"
    }
   },
   "outputs": [],
   "source": [
    "data_preprocess = DataPreprocess()\n",
    "data_preprocess.remove_stopwords()\n",
    "x_train_oversampled, y_train_oversampled = boostrap_oversampling(data_preprocess.train, data_preprocess.label_train)\n",
    "xgboost_classifier, tfidf_transformer = train_xgboost(x_train_oversampled, y_train_oversampled)\n",
    "predictions = xgboost_classifier.predict(data_preprocess.test)\n",
    "save_output(predictions, \"xgboost\", \"random_search_15_iter\", \"stopwords_bootstrap\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage par Ensemble"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble: CNB, XGBoost, Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prétraitement : sans stopwords, sous-échantillonage, réduction de dimension par somme cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:57:27.379771503Z",
     "start_time": "2024-11-11T20:52:06.043030Z"
    }
   },
   "outputs": [],
   "source": [
    "data_preprocess = DataPreprocess()\n",
    "data_preprocess.remove_stopwords()\n",
    "indeces_to_remove = remove_cum_sum(data_preprocess.train, 0.95)\n",
    "data_preprocess.train = np.delete(data_preprocess.train, indeces_to_remove, axis=1)\n",
    "data_preprocess.test = np.delete(data_preprocess.test, indeces_to_remove, axis=1)\n",
    "X_train_undersampled, y_train_undersampled = random_undersampling(data_preprocess.train, data_preprocess.label_train)\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = []\n",
    "# Validation croisée du voteur\n",
    "for train_index, test_index in kf.split(X_train_undersampled):\n",
    "    # Split données\n",
    "    X_train, X_test = X_train_undersampled[train_index], X_train_undersampled[test_index]\n",
    "    y_train, y_test = y_train_undersampled[train_index], y_train_undersampled[test_index]\n",
    "    model_names = ['ComplementNB', 'XGBoost', 'LogisticRegression']\n",
    "    best_ensemble_model = train_ensemble(X_train, y_train, model_names)    \n",
    "    y_pred = best_ensemble_model.predict(X_test)\n",
    "    score = f1_score(y_test, y_pred)\n",
    "    scores.append(score)\n",
    "\n",
    "mean_score = np.mean(scores)\n",
    "print(\"Score F1 de validation du voteur: \", mean_score)\n",
    "\n",
    "predictions_voter = best_ensemble_model.predict(data_preprocess.test)\n",
    "save_output(predictions_voter, \"ensemble_cnb_xgboost_logreg\", \"random_search_15_iter\", \"stopwords_undersampling_cumulative_sum\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prétraitement : sans stopwords, sous-échantillonage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:57:27.379981242Z",
     "start_time": "2024-11-11T20:52:20.612805Z"
    }
   },
   "outputs": [],
   "source": [
    "data_preprocess = DataPreprocess()\n",
    "data_preprocess.remove_stopwords()\n",
    "X_train_undersampled, y_train_undersampled = random_undersampling(data_preprocess.train, data_preprocess.label_train)\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = []\n",
    "# Validation croisée du voteur\n",
    "for train_index, test_index in kf.split(X_train_undersampled):\n",
    "    # Split données\n",
    "    X_train, X_test = X_train_undersampled[train_index], X_train_undersampled[test_index]\n",
    "    y_train, y_test = y_train_undersampled[train_index], y_train_undersampled[test_index]\n",
    "    model_names = ['ComplementNB', 'XGBoost', 'LogisticRegression']\n",
    "    best_ensemble_model = train_ensemble(X_train, y_train, model_names)    \n",
    "    y_pred = best_ensemble_model.predict(X_test)\n",
    "    score = f1_score(y_test, y_pred)\n",
    "    scores.append(score)\n",
    "\n",
    "mean_score = np.mean(scores)\n",
    "print(\"Score F1 de validation du voteur: \", mean_score)\n",
    "\n",
    "predictions_voter = best_ensemble_model.predict(data_preprocess.test)\n",
    "save_output(predictions_voter, \"ensemble_cnb_xgboost_logreg\", \"random_search_15_iter\", \"stopwords_undersampling\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble: Complement Naive Bayes, XGBoost, SVC, SGD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prétraitement: sans stopwords, sous-échantillonage, réduction de dimension par somme cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocess = DataPreprocess()\n",
    "data_preprocess.remove_stopwords()\n",
    "indeces_to_remove = remove_cum_sum(data_preprocess.train, 0.95)\n",
    "data_preprocess.train = np.delete(data_preprocess.train, indeces_to_remove, axis=1)\n",
    "data_preprocess.test = np.delete(data_preprocess.test, indeces_to_remove, axis=1)\n",
    "X_train_undersampled, y_train_undersampled = random_undersampling(data_preprocess.train, data_preprocess.label_train)\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = []\n",
    "# Validation croisée du voteur\n",
    "for train_index, test_index in kf.split(X_train_undersampled):\n",
    "    # Split données\n",
    "    X_train, X_test = X_train_undersampled[train_index], X_train_undersampled[test_index]\n",
    "    y_train, y_test = y_train_undersampled[train_index], y_train_undersampled[test_index]\n",
    "    model_names = ['ComplementNB', 'XGBoost', 'SVC', 'SGD']\n",
    "    best_ensemble_model = train_ensemble(X_train, y_train, model_names)    \n",
    "    y_pred = best_ensemble_model.predict(X_test)\n",
    "    score = f1_score(y_test, y_pred)\n",
    "    scores.append(score)\n",
    "\n",
    "mean_score = np.mean(scores)\n",
    "print(\"Score F1 de validation du voteur: \", mean_score)\n",
    "\n",
    "predictions_voter = best_ensemble_model.predict(data_preprocess.test)\n",
    "save_output(predictions_voter, \"ensemble_cnb_xgboost_svc_sgd\", \"random_search_15_iter\", \"stopwords_undersampling_cumulative_sum\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
