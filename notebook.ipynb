{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aMTO_mUtK7Xy"
      },
      "source": [
        "# Importer les librairies, et fichiers .py auxiliaires"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aDxdetLcJCvp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from preprocess_data import *\n",
        "from bayes_classifier import BayesClassifier\n",
        "from complement_naive_bayes import train_cnb_with_tfidf, train_cnb\n",
        "from ensemble_learning import train_ensemble\n",
        "\n",
        "from save_output import save_output"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploration de données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sHdKFfvqLWn-"
      },
      "source": [
        "# Jalon 1) Naive de Bayes vanille\n",
        "K-Fold Validation croisée ($k = 7)$:\n",
        "- α: Lissage du postérieur de Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "iD7VY-FYJE02",
        "outputId": "a6dae65d-3d11-40f9-c380-6c51f2aef693"
      },
      "outputs": [],
      "source": [
        "data_preprocess = DataPreprocess()\n",
        "bayes_classifier = BayesClassifier()\n",
        "best_lps, best_f1 = bayes_classifier.hyperparameter_tuning(data_preprocess.train, data_preprocess.label_train)\n",
        "print(best_lps, best_f1)\n",
        "tuned_bayes_classifier = BayesClassifier()\n",
        "tuned_bayes_classifier.fit(data_preprocess.train, data_preprocess.label_train, best_lps)\n",
        "predictions = np.array([tuned_bayes_classifier.predict(x_i) for x_i in data_preprocess.test])\n",
        "save_output(predictions, \"bayes\", best_lps, \"stopwords\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Jalon 2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Naive Bayes Complement (avec TFIDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_preprocess = DataPreprocess()\n",
        "complement_naive_bayes, tfidf_transformer = train_cnb_with_tfidf(data_preprocess.train, data_preprocess.label_train)\n",
        "tfidf_test = tfidf_transformer.transform(data_preprocess.test)\n",
        "predictions = complement_naive_bayes.predict(tfidf_test)\n",
        "save_output(predictions, \"cnb\", \"random_search_50_iter\", \"tfidf\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Naive Bayes Complement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_preprocess = DataPreprocess()\n",
        "complement_naive_bayes = train_cnb(data_preprocess.train, data_preprocess.label_train)\n",
        "predictions = complement_naive_bayes.predict(data_preprocess.test)\n",
        "save_output(predictions, \"cnb\", \"random_search_50_iter\", \"no_preprocessing\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Apprentissage par Ensemble"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CNB, XGBoost, Logistic Regression sans stopwords, sous-échantillonage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "[CV 1/2] END ...model__alpha=0.3851694527491273;, score=0.687 total time=   3.4s\n",
            "[CV 2/2] END ...model__alpha=0.3851694527491273;, score=0.683 total time=   4.0s\n",
            "Best F1 for ComplementNB: 0.6849461126344383\n",
            "Confusion Matrix - Fold 1:\n",
            "[[1298  483]\n",
            " [ 296  853]]\n",
            "\n",
            "Confusion Matrix - Fold 2:\n",
            "[[1275  506]\n",
            " [ 290  859]]\n",
            "\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "[CV 1/2] END model__learning_rate=0.11976270078546496, model__max_depth=5, model__n_estimators=200, model__subsample=0.8411053504286575;, score=0.628 total time=  53.7s\n",
            "[CV 2/2] END model__learning_rate=0.11976270078546496, model__max_depth=5, model__n_estimators=200, model__subsample=0.8411053504286575;, score=0.634 total time=  54.3s\n",
            "Best F1 for XGBClassifier: 0.6313404243152057\n",
            "Confusion Matrix - Fold 1:\n",
            "[[1498  283]\n",
            " [ 493  656]]\n",
            "\n",
            "Confusion Matrix - Fold 2:\n",
            "[[1466  315]\n",
            " [ 469  680]]\n",
            "\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "[CV 1/2] END model__C=5.588135039273247, model__penalty=l1, model__solver=liblinear;, score=0.587 total time=   1.8s\n",
            "[CV 2/2] END model__C=5.588135039273247, model__penalty=l1, model__solver=liblinear;, score=0.604 total time=   1.8s\n",
            "Best F1 for LogisticRegression: 0.5959325131042796\n",
            "Confusion Matrix - Fold 1:\n",
            "[[1350  431]\n",
            " [ 492  657]]\n",
            "\n",
            "Confusion Matrix - Fold 2:\n",
            "[[1306  475]\n",
            " [ 447  702]]\n",
            "\n",
            "predictions saved in output/20241110/195910_ensemble_cnb_xgboost_logreg_random_search_15_iter_stopwords.csv\n",
            "already same predictions saved in submissions? None\n",
            "already same predictions saved in output?\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "invalid literal for int() with base 10: '[0]'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m best_ensemble_model \u001b[39m=\u001b[39m train_ensemble(X_train_undersampled, y_train_undersampled, model_names)\n\u001b[0;32m      6\u001b[0m predictions_voter \u001b[39m=\u001b[39m best_ensemble_model\u001b[39m.\u001b[39mpredict(data_preprocess\u001b[39m.\u001b[39mtest)\n\u001b[1;32m----> 7\u001b[0m save_output(predictions_voter, \u001b[39m\"\u001b[39;49m\u001b[39mensemble_cnb_xgboost_logreg\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mrandom_search_15_iter\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstopwords\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
            "File \u001b[1;32mc:\\Users\\Kamen\\ML\\A24\\IFT3395\\kaggle_competition\\save_output.py:47\u001b[0m, in \u001b[0;36msave_output\u001b[1;34m(predictions, classifier, params, transformations)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39malready same predictions saved in submissions?\u001b[39m\u001b[39m\"\u001b[39m, verify_submissions(predictions))\n\u001b[0;32m     46\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39malready same predictions saved in output?\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 47\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m verify_output(predictions, path):\n\u001b[0;32m     48\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m, file)\n\u001b[0;32m     50\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mNumber of 0:\u001b[39m\u001b[39m'\u001b[39m, np\u001b[39m.\u001b[39msum(predictions \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m))\n",
            "File \u001b[1;32mc:\\Users\\Kamen\\ML\\A24\\IFT3395\\kaggle_competition\\save_output.py:25\u001b[0m, in \u001b[0;36mverify_output\u001b[1;34m(predictions, newly_saved)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root, file), \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m     24\u001b[0m     lines \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mreadlines()[\u001b[39m1\u001b[39m:]\n\u001b[1;32m---> 25\u001b[0m label_file \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39mint\u001b[39m(label\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mstrip()) \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m lines])\n\u001b[0;32m     26\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mall(label_file \u001b[39m==\u001b[39m predictions):\n\u001b[0;32m     27\u001b[0m     all_files\u001b[39m.\u001b[39mappend(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root, file))\n",
            "File \u001b[1;32mc:\\Users\\Kamen\\ML\\A24\\IFT3395\\kaggle_competition\\save_output.py:25\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root, file), \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m     24\u001b[0m     lines \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mreadlines()[\u001b[39m1\u001b[39m:]\n\u001b[1;32m---> 25\u001b[0m label_file \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39mint\u001b[39;49m(label\u001b[39m.\u001b[39;49msplit(\u001b[39m\"\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mstrip()) \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m lines])\n\u001b[0;32m     26\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mall(label_file \u001b[39m==\u001b[39m predictions):\n\u001b[0;32m     27\u001b[0m     all_files\u001b[39m.\u001b[39mappend(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root, file))\n",
            "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '[0]'"
          ]
        }
      ],
      "source": [
        "data_preprocess = DataPreprocess()\n",
        "data_preprocess.remove_stopwords()\n",
        "X_train_undersampled, y_train_undersampled = random_undersampling(data_preprocess.train, data_preprocess.label_train)\n",
        "model_names = ['ComplementNB', 'XGBoost', 'LogisticRegression']\n",
        "best_ensemble_model = train_ensemble(X_train_undersampled, y_train_undersampled, model_names)\n",
        "predictions_voter = best_ensemble_model.predict(data_preprocess.test)\n",
        "save_output(predictions_voter, \"ensemble_cnb_xgboost_logreg\", \"random_search_15_iter\", \"stopwords\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
